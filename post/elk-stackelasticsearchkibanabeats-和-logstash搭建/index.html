<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>ELK Stack(Elasticsearch、Kibana、Beats 和 Logstash)搭建日志收集系统 - 梧桐碎梦</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="梧桐碎梦" /><meta name="description" content="Elasticsearch用于搜索、分析数据。
Kibana用于展示数据。
Beats用于收集数据。
Logstash用于集中、转换和存储数据。
" /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.85.0 with theme even" />


<link rel="canonical" href="https://wutongsuimeng.github.io/post/elk-stackelasticsearchkibanabeats-%E5%92%8C-logstash%E6%90%AD%E5%BB%BA/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">



<link href="/sass/main.min.cb68f97bc9cece255d217346d970e3c62623408634e500c330a62fadabbbe77c.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="ELK Stack(Elasticsearch、Kibana、Beats 和 Logstash)搭建日志收集系统" />
<meta property="og:description" content="Elasticsearch用于搜索、分析数据。
Kibana用于展示数据。
Beats用于收集数据。
Logstash用于集中、转换和存储数据。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://wutongsuimeng.github.io/post/elk-stackelasticsearchkibanabeats-%E5%92%8C-logstash%E6%90%AD%E5%BB%BA/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-10-11T23:59:00+08:00" />
<meta property="article:modified_time" content="2021-10-11T23:59:00+08:00" />

<meta itemprop="name" content="ELK Stack(Elasticsearch、Kibana、Beats 和 Logstash)搭建日志收集系统">
<meta itemprop="description" content="Elasticsearch用于搜索、分析数据。
Kibana用于展示数据。
Beats用于收集数据。
Logstash用于集中、转换和存储数据。"><meta itemprop="datePublished" content="2021-10-11T23:59:00+08:00" />
<meta itemprop="dateModified" content="2021-10-11T23:59:00+08:00" />
<meta itemprop="wordCount" content="5814">
<meta itemprop="keywords" content="Elasticsearch,Kibana,Beats,Logstash,日志系统," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="ELK Stack(Elasticsearch、Kibana、Beats 和 Logstash)搭建日志收集系统"/>
<meta name="twitter:description" content="Elasticsearch用于搜索、分析数据。
Kibana用于展示数据。
Beats用于收集数据。
Logstash用于集中、转换和存储数据。"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">梧桐碎梦</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">首页</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">标签</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">分类</li>
      </a>
  </ul>

  


</nav>

  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">梧桐碎梦</a>
</div>





<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">首页</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">标签</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">分类</a>
      </li>
  </ul>
</nav>

    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">ELK Stack(Elasticsearch、Kibana、Beats 和 Logstash)搭建日志收集系统</h1>

      <div class="post-meta">
        <span class="post-time"> 2021-10-11 23:59:00 </span>
        <div class="post-category">
            <a href="/categories/%E8%BF%90%E7%BB%B4/"> 运维 </a>
            </div>
          <span class="more-meta"> 约 5814 字 </span>
          <span class="more-meta"> 预计阅读 12 分钟 </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#使用docker搭建elk">使用Docker搭建ELK</a>
      <ul>
        <li><a href="#新建配置文件">新建配置文件</a></li>
        <li><a href="#准备创建docker-compose文件">准备创建docker-compose文件</a></li>
        <li><a href="#配置认证并启动elk">配置认证并启动ELK</a></li>
      </ul>
    </li>
    <li><a href="#spring集成elk">Spring集成ELK</a>
      <ul>
        <li><a href="#添加依赖">添加依赖</a></li>
        <li><a href="#项目配置">项目配置</a></li>
        <li><a href="#logstash配置">logstash配置</a></li>
        <li><a href="#查看日志">查看日志</a></li>
        <li><a href="#从项目传入自定义索引">从项目传入自定义索引</a></li>
      </ul>
    </li>
    <li><a href="#使用filebeats收集日志">使用Filebeats收集日志</a>
      <ul>
        <li><a href="#filebeats的docker安装">Filebeats的docker安装</a></li>
      </ul>
    </li>
    <li><a href="#自定义收集的日志内容">自定义收集的日志内容</a>
      <ul>
        <li><a href="#grok插件">grok插件</a></li>
        <li><a href="#匹配单行日志">匹配单行日志</a></li>
        <li><a href="#匹配多行日志">匹配多行日志</a></li>
        <li><a href="#filebeat日志重复">filebeat日志重复</a></li>
      </ul>
    </li>
    <li><a href="#filebeat收集多个日志文件并添加到不同的索引">filebeat收集多个日志文件并添加到不同的索引</a>
      <ul>
        <li><a href="#将日志产生的时间替换timestamp">将日志产生的时间替换@timestamp</a></li>
        <li><a href="#参考">参考</a></li>
      </ul>
    </li>
    <li><a href="#配置文件">配置文件</a></li>
    <li><a href="#发送告警日志到钉">发送告警日志到钉</a>
      <ul>
        <li><a href="#创建一个连接器">创建一个连接器</a></li>
        <li><a href="#测试">测试</a></li>
      </ul>
    </li>
    <li><a href="#参考-1">参考</a></li>
  </ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>Elasticsearch用于搜索、分析数据。</p>
<p>Kibana用于展示数据。</p>
<p>Beats用于收集数据。</p>
<p>Logstash用于集中、转换和存储数据。</p>
<p>日志的主要处理流程为下图（忘了从哪找到的图）：</p>
<p><img src="/media/ELK%20Stack(Elasticsearch%E3%80%81Kibana%E3%80%81Beats%20%E5%92%8C%20Logstash)%E6%90%AD%E5%BB%BA%208aaac5c86012479a8765cbad898592c3/Untitled.png" alt="ELK%20Stack(Elasticsearch%E3%80%81Kibana%E3%80%81Beats%20%E5%92%8C%20Logstash)%E6%90%AD%E5%BB%BA%208aaac5c86012479a8765cbad898592c3/Untitled.png"></p>
<h1 id="使用docker搭建elk">使用Docker搭建ELK</h1>
<h2 id="新建配置文件">新建配置文件</h2>
<p>在elastic/config目录下，创建ElasticSearch的配置文件：</p>
<pre><code class="language-yaml"># es01.yml
cluster.name: &quot;docker-cluster&quot;
network.host: 0.0.0.0
</code></pre>
<p>同目录下创建kibnana的配置文件：</p>
<pre><code class="language-yaml"># kib01.yml
server.host: &quot;0&quot;
elasticsearch.hosts: [ &quot;http://elasticsearch:9200&quot; ]
monitoring.ui.container.elasticsearch.enabled: true
xpack.encryptedSavedObjects.encryptionKey: b014b39f62fd1d9a0b1dac766c0e51f5
xpack.reporting.encryptionKey: 9e069cbc6b68796799f96f057ce6c5f5
xpack.security.encryptionKey: 1e0cf9eb23cbfd00d8ba113cb5327bb5
</code></pre>
<p>在elastic/config/logstash目录下，创建logstash的配置文件：</p>
<pre><code class="language-yaml"># logstash.yml
http.host: &quot;0.0.0.0&quot;
xpack.monitoring.elasticsearch.hosts: [ &quot;https://es01:9200&quot; ]
xpack.monitoring.enabled: true
xpack.monitoring.elasticsearch.username: elastic
xpack.monitoring.elasticsearch.password: TsfYfefVTuDfwDg3IITK
xpack.monitoring.elasticsearch.ssl.certificate_authority: /usr/share/elasticsearch/config/certificates/ca/ca.crt
</code></pre>
<p>在同目录下，创建logstash管理pipeline的配置文件：</p>
<pre><code class="language-yaml"># pipelines.yml

# This file is where you define your pipelines. You can define multiple.
# # For more information on multiple pipelines, see the documentation:
# #   https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html
#
- pipeline.id: main
  path.config: &quot;/usr/share/logstash/pipeline&quot;
</code></pre>
<p>在elastic/config/logstash/pipeline目录下，创建logstash收集器配置文件：</p>
<pre><code># logstash.conf
input {
    tcp {
        mode =&gt; &quot;server&quot;
        host =&gt; &quot;0.0.0.0&quot;
        port =&gt; 4560
        codec =&gt; json_lines
    }
}
output {
    elasticsearch {
        hosts =&gt; [&quot;https://es01:9200&quot;]
        index =&gt; &quot;springboot-test-%{+YYYY.MM.dd}&quot;
        user =&gt; elastic
        password =&gt; TsfYfefVTuDfwDg3IITK
        ssl_certificate_verification =&gt; false #关闭ssl
    }
    stdout{codec =&gt; rubydebug}
}
</code></pre>
<h2 id="准备创建docker-compose文件">准备创建docker-compose文件</h2>
<p>在elastic/config/elasticsearch/certificaes目录下创建instances.yml文件：</p>
<pre><code class="language-yaml"># instances.yml
instances:
  - name: es01
    dns:
      - es01
      - localhost
    ip:
      - 127.0.0.1

  - name: 'kib01'
    dns:
      - kib01
      - localhost

  - name: 'logstash'
    dns:
      - logstash
      - localhost
    ip:
      - 127.0.0.1
</code></pre>
<p>在elastic目录下，创建认证的文件：</p>
<pre><code class="language-yaml"># create-certs.yml
version: '2.2'

services:
  create_certs:
    image: docker.elastic.co/elasticsearch/elasticsearch:${VERSION}
    container_name: create_certs
    command: &gt;
      bash -c '
        yum install -y -q -e 0 unzip;
        if [[ ! -f /certs/bundle.zip ]]; then
          bin/elasticsearch-certutil cert --silent --pem --in config/certificates/instances.yml -out /certs/bundle.zip;
          unzip /certs/bundle.zip -d /certs;
        fi;
        chown -R 1000:0 /certs
      '
    working_dir: /usr/share/elasticsearch
    volumes:
      - ./certs:/certs
      - ./config/elasticsearch/certificates:/usr/share/elasticsearch/config/certificates
    networks:
      - elastic

volumes:
  certs:
    driver: local

networks:
  elastic:
    driver: bridge
</code></pre>
<p>在同目录下，创建环境文件，方便统一管理docker版本：</p>
<pre><code># .env
COMPOSE_PROJECT_NAME=es
CERTS_DIR=/usr/share/elasticsearch/config/certificates   # 这个为docker容器里面的位置
VERSION=7.13.4
</code></pre>
<p>同目录下，创建docker-compose文件：</p>
<pre><code class="language-yaml"># elastic-docker-tls.yml
version: '2.2'

services:
  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:${VERSION}
    container_name: es01
    environment:
      - cluster.name=es-docker
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot;
      - xpack.license.self_generated.type=trial 
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=true 
      - xpack.security.http.ssl.key=$CERTS_DIR/es01/es01.key
      - xpack.security.http.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt
      - xpack.security.http.ssl.certificate=$CERTS_DIR/es01/es01.crt
      - xpack.security.transport.ssl.enabled=true 
      - xpack.security.transport.ssl.verification_mode=certificate 
      - xpack.security.transport.ssl.certificate_authorities=$CERTS_DIR/ca/ca.crt
      - xpack.security.transport.ssl.certificate=$CERTS_DIR/es01/es01.crt
      - xpack.security.transport.ssl.key=$CERTS_DIR/es01/es01.key
      - TZ=Asia/Shanghai
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - data01:/usr/share/elasticsearch/data
      - ./certs:$CERTS_DIR
      - ./config/es01.yml:/usr/share/elasticsearch/config/elasticsearch.yml
    ports:
      - 9200:9200
    networks:
      - elastic

    healthcheck:
      test: curl --cacert $CERTS_DIR/ca/ca.crt -s https://localhost:9200 &gt;/dev/null; if [[ $$? == 52 ]]; then echo 0; else echo 1; fi
      interval: 30s
      timeout: 10s
      retries: 5

  kib01:
    image: docker.elastic.co/kibana/kibana:${VERSION}
    container_name: kib01
    depends_on: {&quot;es01&quot;: {&quot;condition&quot;: &quot;service_healthy&quot;}}
    ports:
      - 5601:5601
    environment:
      SERVERNAME: localhost
      ELASTICSEARCH_URL: https://es01:9200
      ELASTICSEARCH_HOSTS: https://es01:9200
      ELASTICSEARCH_USERNAME: kibana_system
      ELASTICSEARCH_PASSWORD: 1Y51Fvgcq9Tv5oG1MWSr
      ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES: $CERTS_DIR/ca/ca.crt
      SERVER_SSL_ENABLED: &quot;true&quot;
      SERVER_SSL_KEY: $CERTS_DIR/kib01/kib01.key
      SERVER_SSL_CERTIFICATE: $CERTS_DIR/kib01/kib01.crt
      I18N_LOCALE: zh-CN
      TZ: Asia/Shanghai
    volumes:
      - ./certs:$CERTS_DIR
      - ./config/kib01.yml:/usr/share/kibana/config/kibana.yml
    networks:
      - elastic
  logstash:
    image: docker.elastic.co/logstash/logstash:${VERSION}
    container_name: logstash
    depends_on: {&quot;es01&quot;: {&quot;condition&quot;: &quot;service_healthy&quot;}}
    volumes:
      - ./config/logstash/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./config/logstash/pipelines.yml:/usr/share/logstash/config/pipelines.yml
      - ./config/logstash/pipeline:/usr/share/logstash/pipeline
      - ./certs:$CERTS_DIR
    ports:
      - 4560:4560
      - 4561:4561
    environment:
      SERVERNAME: localhost
      ELASTICSEARCH_URL: https://es01:9200
      ELASTICSEARCH_HOSTS: https://es01:9200
      ELASTICSEARCH_USERNAME: logstash_system
      ELASTICSEARCH_PASSWORD: psvTdxGicq3R0evjCLHv
      ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES: $CERTS_DIR/ca/ca.crt
      SERVER_SSL_ENABLED: &quot;true&quot;
      SERVER_SSL_KEY: $CERTS_DIR/logstash/logstash.key
      SERVER_SSL_CERTIFICATE: $CERTS_DIR/logstash/logstash.crt
      I18N_LOCALE: zh-CN
      TZ: Asia/Shanghai
    networks:
      - elastic

volumes:
  data01:
    driver: local
  certs:
    driver: local

networks:
  elastic:
    driver: bridge
</code></pre>
<p>建议从官方拉取docker文件，但是官方网址比较慢，也可以改为从其他镜像仓库下载，例如把 <code>[docker.elastic.co/kibana/kibana:${VERSION}](http://docker.elastic.co/kibana/kibana:${VERSION})</code> 官方地址前缀去掉，变成 <code>kibana:${VERSION}</code>，其他images也类似。</p>
<h2 id="配置认证并启动elk">配置认证并启动ELK</h2>
<p>首先创建认证：</p>
<pre><code class="language-bash">$ docker-compose -f create-certs.yml run --rm create_certs
</code></pre>
<p>启动所有服务：</p>
<pre><code class="language-bash">$ docker-compose -f elastic-docker-tls.yml up -d
</code></pre>
<p>生成用户密码：</p>
<pre><code class="language-bash">$ docker exec es01 /bin/bash -c &quot;bin/elasticsearch-setup-passwords \
auto --batch --url https://es01:9200&quot;
</code></pre>
<p>将生成的密码记录下来，将kibana_system的密码复制到elastic-docker-tls.yml文件中的kib01的ELASTICSEARCH_PASSWORD，将logstash_system的密码复制到elastic-docker-tls.yml文件中的logstash的ELASTICSEARCH_PASSWORD。</p>
<p>停止docker-compose：</p>
<pre><code class="language-bash">$ docker-compose -f elastic-docker-tls.yml stop
</code></pre>
<p>再启动docker-compose即可。</p>
<p>启动成功后，用命令 <code>docker network inspect es_elastic</code>能看到应用都连接到了同一个网络。</p>
<p>检查logstash是否正常启动，通过命令 <code>docker logs logstash</code>查看日志是否有error。</p>
<h1 id="spring集成elk">Spring集成ELK</h1>
<p>将Spring产生的日志发送到logstash，logstash对数据进行过滤后，再发送到elasticsearch，再通过kibnana查看数据。</p>
<h2 id="添加依赖">添加依赖</h2>
<p>Spring使用的是logback，原本是想使用log4j，但没能集成成功。</p>
<p>添加logstash依赖（核心），lombok和spring-boot-starter-web：</p>
<pre><code class="language-xml">&lt;!-- pom.xml --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
    &lt;artifactId&gt;lombok&lt;/artifactId&gt;
    &lt;optional&gt;true&lt;/optional&gt;
    &lt;version&gt;1.18.20&lt;/version&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;net.logstash.logback&lt;/groupId&gt;
    &lt;artifactId&gt;logstash-logback-encoder&lt;/artifactId&gt;
    &lt;version&gt;6.6&lt;/version&gt;
&lt;/dependency&gt;
</code></pre>
<p>集成logstash的详细使用可以参考：</p>
<p><a href="https://github.com/logstash/logstash-logback-encoder">GitHub - logstash/logstash-logback-encoder: Logback JSON encoder and appenders</a></p>
<h2 id="项目配置">项目配置</h2>
<p>配置日志配置文件logback.xml，配置文件放在src/main/resource下：</p>
<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;configuration  scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt;
    &lt;include resource=&quot;org/springframework/boot/logging/logback/base.xml&quot; /&gt;
    &lt;contextName&gt;logback&lt;/contextName&gt;

    &lt;appender name=&quot;logstash&quot; class=&quot;net.logstash.logback.appender.LogstashTcpSocketAppender&quot;&gt;
        &lt;destination&gt;127.0.0.1:4560&lt;/destination&gt;
        &lt;encoder class=&quot;net.logstash.logback.encoder.LogstashEncoder&quot; /&gt;
    &lt;/appender&gt;

    &lt;!--输出到控制台--&gt;
    &lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;%d{HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36} - %msg%n&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;root level=&quot;info&quot;&gt;
        &lt;appender-ref ref=&quot;logstash&quot;/&gt;
        &lt;appender-ref ref=&quot;console&quot; /&gt;
    &lt;/root&gt;
&lt;/configuration&gt;
</code></pre>
<p><code>&lt;destination&gt;127.0.0.1:4560&lt;/destination&gt;</code>logstash ip和暴露的端口，logback就是通过这个地址把日志发送给logstash。</p>
<p>并在application.properties文件配置日志输出级别和日志配置文件位置：</p>
<pre><code># application.properties
logging.level.root=info
logging.config=classpath:logback.xml
</code></pre>
<p>打印日志的代码：</p>
<pre><code class="language-java">// TestController.java
@RestController
@Slf4j
public class TestController {

    @GetMapping(value = &quot;/log4j2&quot;)
    public String testLog(){
        try {
            log.info(&quot;Hello 这是 info message. 信息&quot;);
            log.error(&quot;Hello 这是 error message. 报警&quot;);
            log.warn(&quot;Hello 这是 warn message. 警告&quot;);
            log.debug(&quot;Hello 这是 debug message. 调试&quot;);
            List&lt;String&gt; list = new ArrayList&lt;&gt;();
            System.out.println(list.get(2));
        } catch (Exception e) {
            log.error(&quot;testLog&quot;, e);
        }
        return &quot;&quot;;
    }
}
</code></pre>
<h2 id="logstash配置">logstash配置</h2>
<p>在logstash.conf配置收集器，其实前面已经配置过了。更改了配置之后需要重启logstash：</p>
<pre><code># logstash.conf
input {
    tcp {
        mode =&gt; &quot;server&quot;
        host =&gt; &quot;0.0.0.0&quot;  #不限定输入的ip地址
        port =&gt; 4560  #监听的端口
        codec =&gt; json_lines #解析器
    }
}
output {
    elasticsearch { 
        hosts =&gt; [&quot;https://es01:9200&quot;]
        index =&gt; &quot;springboot-test-%{+YYYY.MM.dd}&quot;
        user =&gt; elastic
        password =&gt; TsfYfefVTuDfwDg3IITK
        ssl_certificate_verification =&gt; false
    }
    stdout{codec =&gt; rubydebug}
}
</code></pre>
<h2 id="查看日志">查看日志</h2>
<p>可以在logstash中看到接收到的日志。</p>
<p>接下来，使用账号elastic登陆kibana，页面地址为http://ip:5601</p>
<p>在索引管理能看到传入的数据。</p>
<p><img src="/media/ELK%20Stack(Elasticsearch%E3%80%81Kibana%E3%80%81Beats%20%E5%92%8C%20Logstash)%E6%90%AD%E5%BB%BA%208aaac5c86012479a8765cbad898592c3/Untitled%201.png" alt="ELK%20Stack(Elasticsearch%E3%80%81Kibana%E3%80%81Beats%20%E5%92%8C%20Logstash)%E6%90%AD%E5%BB%BA%208aaac5c86012479a8765cbad898592c3/Untitled%201.png"></p>
<p>然后去到索引模式，创建索引模式</p>
<p><img src="/media/ELK%20Stack(Elasticsearch%E3%80%81Kibana%E3%80%81Beats%20%E5%92%8C%20Logstash)%E6%90%AD%E5%BB%BA%208aaac5c86012479a8765cbad898592c3/Untitled%202.png" alt="ELK%20Stack(Elasticsearch%E3%80%81Kibana%E3%80%81Beats%20%E5%92%8C%20Logstash)%E6%90%AD%E5%BB%BA%208aaac5c86012479a8765cbad898592c3/Untitled%202.png"></p>
<p>索引名字同logstash.conf中output中的index。时间筛选字段名称处选择 @timestamp，方便我们后边按照时间段筛选数据</p>
<p>然后去到Discover下，选择对应的索引模式及日志时间，便能看到数据</p>
<p><img src="/media/ELK%20Stack(Elasticsearch%E3%80%81Kibana%E3%80%81Beats%20%E5%92%8C%20Logstash)%E6%90%AD%E5%BB%BA%208aaac5c86012479a8765cbad898592c3/Untitled%203.png" alt="ELK%20Stack(Elasticsearch%E3%80%81Kibana%E3%80%81Beats%20%E5%92%8C%20Logstash)%E6%90%AD%E5%BB%BA%208aaac5c86012479a8765cbad898592c3/Untitled%203.png"></p>
<p>关于logstash的ssl配置可以参考：</p>
<p><a href="https://discuss.elastic.co/t/error-unable-to-find-valid-certification-path/122304/7">Error unable to find valid certification path</a></p>
<p><a href="https://www.elastic.co/guide/en/logstash/7.14/monitoring-internal-collection-legacy.html">Collect Logstash monitoring data using legacy collectors | Logstash Reference [7.14] | Elastic</a></p>
<h2 id="从项目传入自定义索引">从项目传入自定义索引</h2>
<p>上面的配置只能用于一个项目，但是不可能一个ELK只有一个项目，所以为了让ELK接入多个项目，项目传入自定义的索引。</p>
<p>修改logback.xml文件，增加了<customFields>标签：</p>
<pre><code class="language-xml">&lt;!-- logback.xml --&gt;

&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;configuration  scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt;
    &lt;include resource=&quot;org/springframework/boot/logging/logback/base.xml&quot; /&gt;
    &lt;contextName&gt;logback&lt;/contextName&gt;

    &lt;appender name=&quot;logstash&quot; class=&quot;net.logstash.logback.appender.LogstashTcpSocketAppender&quot;&gt;
        &lt;destination&gt;127.0.0.1:4560&lt;/destination&gt;
        &lt;encoder class=&quot;net.logstash.logback.encoder.LogstashEncoder&quot; &gt;
        &lt;customFields&gt;{&quot;appName&quot;: &quot;spring-test2&quot;}&lt;/customFields&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;!--输出到控制台--&gt;
    &lt;appender name=&quot;console&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt;
        &lt;encoder&gt;
            &lt;pattern&gt;%d{HH:mm:ss.SSS} %contextName [%thread] %-5level %logger{36} - %msg%n&lt;/pattern&gt;
        &lt;/encoder&gt;
    &lt;/appender&gt;

    &lt;root level=&quot;info&quot;&gt;
        &lt;appender-ref ref=&quot;logstash&quot;/&gt;
        &lt;appender-ref ref=&quot;console&quot; /&gt;
    &lt;/root&gt;
&lt;/configuration&gt;

</code></pre>
<p>修改logstash.conf</p>
<pre><code># logstash.conf
input {
    tcp {
        mode =&gt; &quot;server&quot;
        host =&gt; &quot;0.0.0.0&quot;
        port =&gt; 4560
        codec =&gt; json_lines
    }
}
output {
    elasticsearch {
        hosts =&gt; [&quot;https://es01:9200&quot;]
        index =&gt; &quot;%{[appName]}-%{+YYYY.MM.dd}&quot;
        user =&gt; elastic
        password =&gt; TsfYfefVTuDfwDg3IITK
        ssl_certificate_verification =&gt; false
    }
    stdout{codec =&gt; rubydebug}
}
</code></pre>
<p>重启logstash便能看到传入的索引。</p>
<h1 id="使用filebeats收集日志">使用Filebeats收集日志</h1>
<p>使用filebeats收集应用的日志文件 <code>*.log</code>，并把日志发送到logstash。</p>
<h2 id="filebeats的docker安装">Filebeats的docker安装</h2>
<pre><code class="language-bash">$ docker run -d \
  --name=filebeat \
  --user=root \
  --volume=&quot;$(pwd)/filebeat.docker.yml:/usr/share/filebeat/filebeat.yml:ro&quot; \
  --volume=&quot;/var/lib/docker/containers:/var/lib/docker/containers:ro&quot; \
  --volume=&quot;/var/run/docker.sock:/var/run/docker.sock:ro&quot; \
  --volume=&quot;/var/log:/logs:ro&quot; \
  docker.elastic.co/beats/filebeat:7.14.0 filebeat 
 
</code></pre>
<p>filebeat.docker.yml文件的配置：</p>
<pre><code class="language-yaml"># filebeat.docker.yml
filebeat.inputs:
- type: log  #日志类型
  enable: true
  paths: # 日志位置，所以在创建docker时需要挂载日志目录
    - /logs/info.log
  fields:                     # 使用 fields 模块添加字段
    address: 192.168.1.3     # address 为字段名称，意义为当前服务器的地址
  fields_under_root: true     # 将新增的字段放在顶级，收集后字段名称显示 host_ip。如果设置为 false，则放在子集，收集后显示为 fields.address
  encoding: UTF-8 #日志编码，如果中文乱码，可以试试GB2312

output.logstash:  # 指定输出插件
  hosts: [&quot;192.168.1.0:4561&quot;]   # logstash的位置
  index: 'test' # 索引名字
</code></pre>
<p>关于 <code>output.logstash</code>的 <code>index</code>，该值会分配给 <code>metadata.beat</code>键，所以可以在logstash收集器的配置文件使用 <code>%{[@metadata][beat]}</code>获取该值。</p>
<p>配置logstash收集器的配置文件：</p>
<pre><code># logstash-filebeats.conf
input {
    beats {
        port =&gt; 4561
    }
}
output {
    elasticsearch {
        hosts =&gt; [&quot;https://es01:9200&quot;]
        index =&gt; &quot;%{[@metadata][beat]}&quot;  
        user =&gt; elastic
        password =&gt; TsfYfefVTuDfwDg3IITK
        ssl_certificate_verification =&gt; false
    }
    stdout{codec =&gt; rubydebug}
}
</code></pre>
<p>filebeats配置文件的详细使用可以参考：</p>
<p><a href="https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-reference-yml.html">filebeat.reference.yml | Filebeat Reference [7.15] | Elastic</a></p>
<p>logstash配置文件的使用可以参考：</p>
<p><a href="https://www.elastic.co/guide/en/beats/filebeat/current/logstash-output.html#_ssl_5">Configure the Logstash output | Filebeat Reference [7.15] | Elastic</a></p>
<p>因为使用了两份配置文件，所以需要重新配置pipelines.yml：</p>
<pre><code class="language-yaml"># pipelines.yml
- pipeline.id: main
  path.config: &quot;/usr/share/logstash/pipeline/logstash.conf&quot;

- pipeline.id: beats
  path.config: &quot;/usr/share/logstash/pipeline/logstash-filebeats.conf&quot;
</code></pre>
<h1 id="自定义收集的日志内容">自定义收集的日志内容</h1>
<p>因为默认收集到日志内容包括了时间、日志类型等众多信息，但我们往往只需要看到程序真正输出的内容，这时候可以使用logstash的grok插件对日志内容进行过滤。</p>
<h2 id="grok插件">grok插件</h2>
<p>grok插件用于过滤切分文本。</p>
<p>基本语法为： <code>%{SYNTAX:SEMANTIC}</code></p>
<p><code>SYNTAX</code>为配置配置类型，可以用内置类型（可以在<a href="https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns">https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns</a>找到），也可以自定义类型；</p>
<p><code>SEMANTIC</code>为匹配文本所赋予的变量名，能在kibana所看到。</p>
<p>例子：</p>
<pre><code class="language-java">%{NUMBER:phone}
</code></pre>
<p>例如要匹配：</p>
<pre><code class="language-java">112.123.1.10 [info] - success
</code></pre>
<p>匹配方式为</p>
<pre><code class="language-java">%{IP:ip} \[%{LOGLEVEL:level}\] - %{WORD:text}
</code></pre>
<p><code>[</code>和 <code>]</code>分别需要进行转义 <code>\[</code>和 <code>\]</code>。其实语法跟正则表达式差不多。</p>
<p>推荐使用<a href="https://grokdebug.herokuapp.com/">https://grokdebug.herokuapp.com/</a>进行调试。</p>
<p>所以此时pipeline配置为：</p>
<pre><code class="language-java">filter {
    grok {
        match =&gt; {&quot;message&quot;=&gt;&quot;%{IP:ip} \[%{LOGLEVEL:level}\] - %{WORD:text}&quot;}
    }
}
</code></pre>
<p>grok插件也支持自定义类型</p>
<p>单独把自定义类型放在一个文件（文件名随便）进行管理，可以用正则表达式，也可以用内置类型</p>
<pre><code class="language-java">USERNAME [a-zA-Z0-9._-]+
TIMESTAMP %{YEAR}-%{MONTHNUM}-%{MONTHDAY} %{TIME}
</code></pre>
<p>在patterns_dir参数下指明自定义类型存放文件所在的目录</p>
<pre><code class="language-java">filter {
    grok {
				patterns_dir =&gt; &quot;/usr/share/logstash/pipeline/patterns&quot;
        match =&gt; {&quot;message&quot;=&gt;&quot;%{IP:ip} \[%{LOGLEVEL:level}\] - %{WORD:text}&quot;}
				overwrite =&gt; [&quot;message&quot;]
    }
}
</code></pre>
<p>用 overwrite 参数来重写默认的 message 字段</p>
<h2 id="匹配单行日志">匹配单行日志</h2>
<p>知道了基本的grok语法后，应用了我们的项目中。例如项目正常的info日志为：</p>
<pre><code class="language-xml">2021-08-11 10:58:10 - [INFO] [org.springframework.amqp.rabbit.connection.CachingConnectionFactory:] Attempting to connect to: [xxx]
</code></pre>
<p>所以对应的匹配方式为：</p>
<pre><code class="language-java">%{TIMESTAMP_ISO8601:timestamp} - \[%{LOGLEVEL:level}\] \[%{JAVACLASS:position}\:\] %{WORD:message}
</code></pre>
<p>如果字符过长，过多使用 <code>*</code>，或者匹配类型 <code>GREEDYDATA</code>和 <code>DATA</code>，可能会导致logstash超时。暂时没有解决办法，只能是尽量具体化匹配。</p>
<h2 id="匹配多行日志">匹配多行日志</h2>
<p>例如java堆栈。</p>
<p>例子：</p>
<pre><code>2021-08-18 18:10:46 - [ERROR] [com.xx.framework.web.handle.ExceptionHandle:] unexpected error /user/detail: Required request body is missing: public com.xx.msg throws java.lang.Exception
org.springframework.http.converter.HttpMessageNotReadableException: Required request body is missing: public com.xx.msg throws java.lang.Exception
        at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.readWithMessageConverters(RequestResponseBodyMethodProcessor.java:161) ~[spring-webmvc-5.2.3.RELEASE.jar!/:5.2.3.RELEASE]
        at org.springframework.web.servlet.mvc.method.annotation.RequestResponseBodyMethodProcessor.resolveArgument(RequestResponseBodyMethodProcessor.java:131) ~[spring-webmvc-5.2.3.RELEASE.jar!/:5.2.3.RELEASE]
        at java.lang.Thread.run(Thread.java:748) [?:1.8.0_191]
</code></pre>
<p>多行日志应该在filebeat中进行预处理，再发送到logstash。因为在logstash中处理多行会造成流混乱和数据损坏。</p>
<p>先在filebeat的配置文件中配置多行：</p>
<pre><code class="language-yaml">multiline.type: pattern
multiline.pattern: '^[0-9]{4}-[0-9]{2}-[0-9]{2}'   # 匹配以日期开头
multiline.negate: true
multiline.match: after
</code></pre>
<p>这个配置的意思是将不符合 <code>pattern</code>条件的行追加到前面符合 <code>pattern</code>条件的行的后面去。</p>
<p><code>pattern</code>为是匹配模式； <code>negate</code>为是否否认匹配模式； <code>match</code>为组合匹配的行的方式，取决于 <code>negate</code>。详细使用可见于：</p>
<p><a href="https://www.elastic.co/guide/en/beats/filebeat/7.14/multiline-examples.html#multiline">Manage multiline messages | Filebeat Reference [7.14] | Elastic</a></p>
<p>接着配置logstash。由于从filebeat传入的日志中存在多行，所以需要添加 <code>(?m)</code>，而且存在换行符，但是普通的 <code>DATA</code>和 <code>GREEDYDATA</code>分别为 <code>.*?</code>和 <code>.*</code>，不能匹配换行符，所以需要使用 <code>(?&lt;message&gt;(.|\r|\n)*)</code>来匹配换行符。</p>
<p>总的logstash配置为：</p>
<pre><code class="language-json">//logstash-filebeats.conf
input {
    beats {
        port =&gt; 4561
    }
}
filter {
    grok {
        match =&gt; {&quot;message&quot;=&gt;&quot;(?m)%{TIMESTAMP_ISO8601:timestamp} - \[%{LOGLEVEL:level}\] \[%{JAVACLASS:position}\:\] (?&lt;message&gt;(.|\r|\n)*)&quot;}
        overwrite =&gt; [&quot;message&quot;]
    }

}
output {
    elasticsearch { 
        hosts =&gt; [&quot;https://es01:9200&quot;]
        index =&gt; &quot;%{[@metadata][beat]}&quot;
        user =&gt; elastic
        password =&gt; WjVINkg1zt2DJXAqjWdu
        ssl_certificate_verification =&gt; false
    }
    stdout{codec =&gt; rubydebug}
}
</code></pre>
<h2 id="filebeat日志重复">filebeat日志重复</h2>
<p>因为filebeat传输保证的是”at least once”，而不是”exactly once”。因为filebeat只有收到logstash的ack了才会认为数据发送成功，否则就会重传。</p>
<p>为了避免重复，有三种办法在filebeat中定义document的唯一id。具体办法可以看官方文档：</p>
<p><a href="https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-deduplication.html#_how_can_i_avoid_duplicates">Deduplicate data | Filebeat Reference [7.15] | Elastic</a></p>
<p>翻译版：</p>
<p><a href="https://juejin.cn/post/6934987274119544840">掘金</a></p>
<p>这里选择在filebeats配置文件中添加add_id处理器,为每个字段生成唯一的id。</p>
<pre><code class="language-yaml">processors:
  - add_id: ~
</code></pre>
<p>注：如果程序写日志时把同一段日志写进了两个日志文件（例如把error日志同时写到了error文件和info文件），filebeat会为其分别添加不同的id，这也会造成重复数据。</p>
<h1 id="filebeat收集多个日志文件并添加到不同的索引">filebeat收集多个日志文件并添加到不同的索引</h1>
<p>在filebeat.yml中配置两个日志文件的地址，并在 <code>fields</code>字段下添加字段 <code>address</code>和 <code>category</code>标识不同的日志文件， <code>fields</code>下的字段可以在logstash.conf中直接使用，例如： <code>if [category]{}</code>和 <code>&quot;%{[category]}-%{[address]}&quot;</code>。不在filebeat配置index，而是在logstash进行处理。</p>
<pre><code class="language-yaml"># filebeat.yml
fields:                     
    address: 192.168.1.0    
    category: test
</code></pre>
<p>在logstash接受这两个字段，并将其配置为index：</p>
<pre><code class="language-yaml"># logstash.conf
output {
  elasticsearch { 
      hosts =&gt; [&quot;https://es01:9200&quot;]
      index =&gt; &quot;%{[category]}-%{[address]}&quot;
      user =&gt; elastic
      password =&gt; WjVINkg1zt2DJXAqjWdu
      ssl_certificate_verification =&gt; false
      document_id =&gt; &quot;%{[@metadata][_id]}&quot;
  }
</code></pre>
<p>所以在kibana能看到index</p>
<h2 id="将日志产生的时间替换timestamp">将日志产生的时间替换@timestamp</h2>
<p>在logstash.conf中将从日志中匹配的timestamp字段代替@timestamp字段</p>
<pre><code class="language-yaml"># logstash.conf
filter {
    grok {
        match =&gt; {&quot;message&quot;=&gt;&quot;(?m)%{TIMESTAMP_ISO8601:timestamp} - \[%{LOGLEVEL:level}\] \[%{JAVACLASS:position}\:\] (?&lt;message&gt;(.|\r|\n)*)&quot;}
        overwrite =&gt; [&quot;message&quot;]
    }
    date {
				# 匹配上文过滤出来的timestamp字段，timestamp格式为yyyy-MM-dd HH:mm:ss，这里指的是日志文件中的日志格式
        match =&gt; [&quot;timestamp&quot;, &quot;yyyy-MM-dd HH:mm:ss&quot;]
				# 将上面匹配的timestamp的值存储到@timestamp
        target =&gt; &quot;@timestamp&quot;
				# 设置时间格式化的时区
        timezone =&gt; &quot;Asia/Shanghai&quot;
    }

    mutate {
			# 去除timestamp键
      remove_field =&gt; [ &quot;timestamp&quot; ]
    }

}
</code></pre>
<p>但是这个方法有问题，会导致logstash和elasticsearch中的看到的日志时间不对，暂时没找到解决的办法。</p>
<h2 id="参考">参考</h2>
<p>第四和第五问：</p>
<p><a href="https://www.jianshu.com/p/f0b245ffa147">Elasticsearch 100问(1-30)</a></p>
<p>关于date：</p>
<p><a href="https://www.elastic.co/guide/en/logstash/7.x/plugins-filters-date.html#plugins-filters-date-timezone">Date filter plugin | Logstash Reference [7.x] | Elastic</a></p>
<p>关于event.set:</p>
<p><a href="https://www.elastic.co/guide/en/logstash/7.x/event-api.html">Event API | Logstash Reference [7.x] | Elastic</a></p>
<p>踩坑：</p>
<p><a href="https://segmentfault.com/a/1190000019911946">ELK开发日记(2) - 超坑爹的Filebeat 7.2.0时区漂移 (UTC+16) 解决方案</a></p>
<p><a href="https://github.com/rootsongjc/kubernetes-handbook/issues/209">容器目录下的日志time字段总是比正常时间晚8小时 · Issue #209 · rootsongjc/kubernetes-handbook</a></p>
<p><a href="https://www.modb.pro/db/97996"></a></p>
<p><a href="http://www.chenyp.com/2017/07/25/kibana-time/">ELK中Kibana组件的时间误差</a></p>
<h1 id="配置文件">配置文件</h1>
<p>所以目前最终的配置文件如下;</p>
<p>filebeat.yml</p>
<pre><code class="language-yaml">filebeat.inputs:
- type: log
  enable: true
  paths: 
    - /logs/test.log
  fields:                     # 使用 fields 模块添加字段
    address: 192.168.1.3     # address 为字段名称
    category: test
  fields_under_root: true     # 将新增的字段放在顶级，收集后字段名称显示 address。如果设置为 false，则放在子集，收集后显示为 fields.address
  encoding: UTF-8 
  multiline.type: pattern
  multiline.pattern: '^[0-9]{4}-[0-9]{2}-[0-9]{2}'
  multiline.negate: true
  multiline.match: after

processors:
  - add_id: ~

output.logstash:
  enable: true
  hosts: [&quot;192.168.1.0:4561&quot;]
</code></pre>
<p>logstash.conf</p>
<pre><code class="language-bash">input {
    beats {
        port =&gt; 4561
    }
}
filter {
    grok {
        match =&gt; {&quot;message&quot;=&gt;&quot;(?m)%{TIMESTAMP_ISO8601:timestamp} - \[%{LOGLEVEL:level}\] \[%{JAVACLASS:position}\:\] (?&lt;message&gt;(.|\r|\n)*)&quot;}
        overwrite =&gt; [&quot;message&quot;]
    }
    date {
        match =&gt; [&quot;timestamp&quot;, &quot;yyyy-MM-dd HH:mm:ss&quot;]
        target =&gt; &quot;@timestamp&quot;
        timezone =&gt; &quot;Asia/Shanghai&quot;
    }

    mutate {
      remove_field =&gt; [ &quot;timestamp&quot; ]
    }

}
output {
  if [@metadata][_id] {
    elasticsearch { 
        hosts =&gt; [&quot;https://es01:9200&quot;]
        index =&gt; &quot;%{[category]}-%{[address]}&quot;
        user =&gt; elastic
        password =&gt; WjVINkg1zt2DJXAqjWdu
        ssl_certificate_verification =&gt; false
        document_id =&gt; &quot;%{[@metadata][_id]}&quot;
    }
  }else {
    elasticsearch { 
        hosts =&gt; [&quot;https://es01:9200&quot;]
        index =&gt; &quot;%{[@metadata][beat]}&quot;
        user =&gt; elastic
        password =&gt; WjVINkg1zt2DJXAqjWdu
        ssl_certificate_verification =&gt; false
    }

  }
    stdout{codec =&gt; rubydebug}
}
</code></pre>
<h1 id="发送告警日志到钉">发送告警日志到钉</h1>
<p><img src="/media/ELK%20Stack(Elasticsearch%E3%80%81Kibana%E3%80%81Beats%20%E5%92%8C%20Logstash)%E6%90%AD%E5%BB%BA%208aaac5c86012479a8765cbad898592c3/Untitled%204.png" alt="Untitled"></p>
<h2 id="创建一个连接器">创建一个连接器</h2>
<p>方法选择POST，URL填入钉钉的webhook地址，添加标头Content-Type:application/json。</p>
<p><img src="/media/ELK%20Stack(Elasticsearch%E3%80%81Kibana%E3%80%81Beats%20%E5%92%8C%20Logstash)%E6%90%AD%E5%BB%BA%208aaac5c86012479a8765cbad898592c3/Untitled%205.png" alt="Untitled"></p>
<p>钉钉的webhook的申请方式：</p>
<p>首先新建一个群聊，如果需要新建一个人的群聊，可以在电脑端，发起群聊，选择同学群。</p>
<p>然后添加群聊机器人，选择自定义即可。</p>
<p><img src="/media/ELK%20Stack(Elasticsearch%E3%80%81Kibana%E3%80%81Beats%20%E5%92%8C%20Logstash)%E6%90%AD%E5%BB%BA%208aaac5c86012479a8765cbad898592c3/Untitled%206.png" alt="Untitled"></p>
<p>这里选择了自定义关键词elastic。然后把webhook地址贴到elastic即可。</p>
<h2 id="测试">测试</h2>
<p>在正文填入：</p>
<pre><code>{&quot;msgtype&quot;: &quot;text&quot;,&quot;text&quot;: {&quot;content&quot;:&quot;elastic发来信息&quot;}}
</code></pre>
<p><img src="/media/ELK%20Stack(Elasticsearch%E3%80%81Kibana%E3%80%81Beats%20%E5%92%8C%20Logstash)%E6%90%AD%E5%BB%BA%208aaac5c86012479a8765cbad898592c3/Untitled%207.png" alt="Untitled"></p>
<p>点击测试</p>
<p>钉钉便能收到信息。</p>
<p><img src="/media/ELK%20Stack(Elasticsearch%E3%80%81Kibana%E3%80%81Beats%20%E5%92%8C%20Logstash)%E6%90%AD%E5%BB%BA%208aaac5c86012479a8765cbad898592c3/Untitled%208.png" alt="Untitled"></p>
<p>发送的正文内容可以看钉钉的文档</p>
<p><a href="https://developers.dingtalk.com/document/robots/custom-robot-access">自定义机器人接入 - 钉钉开放平台</a></p>
<p>正文参数可以参考elastic的文档</p>
<p><a href="https://www.elastic.co/guide/en/kibana/master/create-and-manage-rules.html#defining-rules-actions-details">Create and manage rules | Kibana Guide [master] | Elastic</a></p>
<p><img src="/media/ELK%20Stack(Elasticsearch%E3%80%81Kibana%E3%80%81Beats%20%E5%92%8C%20Logstash)%E6%90%AD%E5%BB%BA%208aaac5c86012479a8765cbad898592c3/Untitled%209.png" alt="Untitled"></p>
<h1 id="参考-1">参考</h1>
<p><a href="https://www.elastic.co/guide/en/elastic-stack-get-started/current/get-started-docker.html#get-started-docker-tls">Running the Elastic Stack on Docker | Getting Started [7.15] | Elastic</a></p>
<p><a href="https://blog.csdn.net/aixiaoyang168/article/details/90548938">Spring Boot 使用 Log4j2 &amp; Logback 输出日志到 EKL_哎_小羊的博客-CSDN博客</a></p>
<p><a href="https://doc.yonyoucloud.com/doc/logstash-best-practice-cn/filter/grok.html">Logstash 最佳实践</a></p>
<p><a href="https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html">Grok filter plugin | Logstash Reference [7.15] | Elastic</a></p>
<p><a href="https://blog.csdn.net/wsdc0521/article/details/106308441">ELK系列(七)、Filebeat+Logstash采集多个日志文件并写入不同的ES索引中_王义凯 的博客-CSDN博客</a></p>
    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">梧桐碎梦</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
        2021-10-11 23:59:00
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/elasticsearch/">Elasticsearch</a>
          <a href="/tags/kibana/">Kibana</a>
          <a href="/tags/beats/">Beats</a>
          <a href="/tags/logstash/">Logstash</a>
          <a href="/tags/%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F/">日志系统</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/%E8%87%AA%E5%AE%9A%E4%B9%89hugo%E7%9A%84even%E4%B8%BB%E9%A2%98%E7%A6%81%E6%AD%A2%E5%A4%8D%E5%88%B6%E4%BB%A3%E7%A0%81%E8%A1%8C%E6%95%B0/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">自定义hugo的even主题，禁止复制代码行数</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        <a class="next" href="/post/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AAgo%E9%A1%B9%E7%9B%AE/">
            <span class="next-text nav-default">自动化构建一个Go项目</span>
            <span class="next-text nav-mobile">下一篇</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  <a href="https://wutongsuimeng.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    由 <a class="hexo-link" href="https://gohugo.io">Hugo</a> 强力驱动
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    主题 - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2021<span class="heart"><i class="iconfont icon-heart"></i></span><span>梧桐碎梦</span>
  </span>
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script src="/lib/highlight/highlight.pack.js?v=20171001"></script>
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>



<script type="text/javascript" src="/js/main.min.457ad251d7627fb9756da373da1c5de180a794987aa9108a3e0648015a240a20.js"></script>








</body>
</html>
